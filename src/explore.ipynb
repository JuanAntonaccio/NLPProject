{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n",
                "\n",
                "It's recommended to use this notebook for exploration purposes.\n",
                "\n",
                "For example: \n",
                "\n",
                "1. You could import the CSV generated by python into your notebook and explore it.\n",
                "2. You could connect to your database using `pandas.read_sql` from this notebook and explore it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (1.4.3)\n",
                        "Requirement already satisfied: numpy>=1.18.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (1.23.1)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2022.1)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: regex in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (2022.7.25)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: matplotlib in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (3.5.2)\n",
                        "Requirement already satisfied: numpy>=1.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (1.23.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
                        "Requirement already satisfied: cycler>=0.10 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
                        "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
                        "Requirement already satisfied: pillow>=6.2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (4.34.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
                        "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Requirement already satisfied: nltk in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (3.7)\n",
                        "Requirement already satisfied: joblib in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
                        "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
                        "Requirement already satisfied: click in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
                        "Requirement already satisfied: regex>=2021.8.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nltk) (2022.7.25)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "! pip install pandas\n",
                "! pip install regex\n",
                "! pip install matplotlib\n",
                "! pip install nltk\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: sklearn in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (0.0)\n",
                        "Requirement already satisfied: scikit-learn in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from sklearn) (1.1.1)\n",
                        "Requirement already satisfied: numpy>=1.17.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.23.1)\n",
                        "Requirement already satisfied: scipy>=1.3.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.1)\n",
                        "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
                        "Requirement already satisfied: joblib>=1.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "! pip install sklearn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import pandas as pd \n",
                "import regex as reg\n",
                "import re\n",
                "import matplotlib.pyplot as plt\n",
                "import unicodedata\n",
                "import nltk\n",
                "import string\n",
                "import pickle\n",
                "\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "from sklearn import model_selection, svm\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from nltk.corpus import stopwords\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<bound method DataFrame.info of                                                     url  is_spam\n",
                            "0     https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                                https://www.hvper.com/     True\n",
                            "2                    https://briefingday.com/m/v4n3i4f3     True\n",
                            "3      https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                           https://briefingday.com/fan     True\n",
                            "...                                                 ...      ...\n",
                            "2994  https://www.smartcitiesworld.net/news/news/dee...    False\n",
                            "2995                      https://www.youtube.com/watch     True\n",
                            "2996  https://techcrunch.com/2019/07/04/an-optimisti...    False\n",
                            "2997  https://www.technologyreview.com/2019/12/20/13...    False\n",
                            "2998       https://www.bbc.com/news/technology-51018758    False\n",
                            "\n",
                            "[2999 rows x 2 columns]>"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Vamos a pasar a 0 y 1 la variable objetivo\n",
                "\n",
                "df_raw['is_spam'] = df_raw['is_spam'].apply(lambda x: 1 if x == True else 0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<bound method DataFrame.info of                                                     url  is_spam\n",
                            "0     https://briefingday.us8.list-manage.com/unsubs...        1\n",
                            "1                                https://www.hvper.com/        1\n",
                            "2                    https://briefingday.com/m/v4n3i4f3        1\n",
                            "3      https://briefingday.com/n/20200618/m#commentform        0\n",
                            "4                           https://briefingday.com/fan        1\n",
                            "...                                                 ...      ...\n",
                            "2994  https://www.smartcitiesworld.net/news/news/dee...        0\n",
                            "2995                      https://www.youtube.com/watch        1\n",
                            "2996  https://techcrunch.com/2019/07/04/an-optimisti...        0\n",
                            "2997  https://www.technologyreview.com/2019/12/20/13...        0\n",
                            "2998       https://www.bbc.com/news/technology-51018758        0\n",
                            "\n",
                            "[2999 rows x 2 columns]>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw.info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 2999 entries, 0 to 2998\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column   Non-Null Count  Dtype \n",
                        "---  ------   --------------  ----- \n",
                        " 0   url      2999 non-null   object\n",
                        " 1   is_spam  2999 non-null   int64 \n",
                        "dtypes: int64(1), object(1)\n",
                        "memory usage: 47.0+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_raw.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1318    https://www.marketwatch.com/story/a-lot-of-bad...\n",
                            "1502    https://www.thecut.com/2020/06/100-days-since-...\n",
                            "2745                      https://wethetrillions.com/quiz\n",
                            "382                           https://briefingday.com/fan\n",
                            "1727    https://www.reuters.com/article/us-health-coro...\n",
                            "2281    https://apnews.com/c9c6eee97277d6e8e71f568cde8...\n",
                            "716                                  https://outlier.nyc/\n",
                            "436     https://www.top500.org/news/japan-captures-top...\n",
                            "433     https://www.cnbc.com/2020/06/22/patagonia-join...\n",
                            "2403    https://apnews.com/318e059fa2712c9624617ccd049...\n",
                            "2382    https://apnews.com/3838b5b207c68546b22f9bd9d62...\n",
                            "812     https://www.newyorker.com/news/annals-of-activ...\n",
                            "1119    https://explore.org/livecams/brown-bears/brown...\n",
                            "2771    https://www.latimes.com/science/story/2020-01-...\n",
                            "196     https://people.com/health/gyms-tries-workout-p...\n",
                            "1403                   https://www.natashaknows.com/about\n",
                            "124     https://www.federalreserve.gov/publications/20...\n",
                            "2373                    https://whyisthisinteresting.com/\n",
                            "336      https://www.morningbrew.com/daily/refer-a-friend\n",
                            "1747                        https://thehustle.co/account/\n",
                            "Name: url, dtype: object"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw['url'].sample(20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    2303\n",
                            "1     696\n",
                            "Name: is_spam, dtype: int64"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_raw['is_spam'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hay spam:  696\n",
                        "Que no son spam :  2303\n",
                        "(2999, 2)\n"
                    ]
                }
            ],
            "source": [
                "# Vamos a ver como esta nuestra variable objetivo en este caso es is_spam\n",
                "df_raw['is_spam'].value_counts()\n",
                "print(\"Hay spam: \",len(df_raw.loc[df_raw.is_spam==1]))\n",
                "print(\"Que no son spam : \",len(df_raw.loc[df_raw.is_spam==0]))\n",
                "print(df_raw.shape)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2369, 2)"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Eliminar los duplicados\n",
                "\n",
                "df_raw = df_raw.drop_duplicates()\n",
                "df_raw = df_raw.reset_index(inplace = False)[['url','is_spam']]\n",
                "df_raw.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Empezamos el proceso de Limipieza de los datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# colocar todos los textos en minusculas\n",
                "df_raw['url'] = df_raw['url'].str.lower()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
                        "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['i', 'me', 'my', 'myself', 'we']\n",
                        "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
                    ]
                }
            ],
            "source": [
                "nltk.download('stopwords')\n",
                "nltk.download('punkt')\n",
                "\n",
                "stopwords = nltk.corpus.stopwords.words('english')\n",
                "punctuation = string.punctuation\n",
                "\n",
                "print(stopwords[:5])\n",
                "print(punctuation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_aux = df_raw.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https briefingday us list manage com unsubscribe</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https www hvper com</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https briefingday com m v n i f</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https briefingday com n m commentform</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https briefingday com fan</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                url  is_spam\n",
                            "0  https briefingday us list manage com unsubscribe        1\n",
                            "1                              https www hvper com         1\n",
                            "2                  https briefingday com m v n i f         1\n",
                            "3             https briefingday com n m commentform        0\n",
                            "4                         https briefingday com fan        1"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "# Proceso de limpieza de datos\n",
                "\n",
                "limpieza = []\n",
                "\n",
                "for p in range(len(df_aux.url)):\n",
                "    desc = df_aux['url'][p]\n",
                "    \n",
                "    #savar la puntuacion\n",
                "    desc = re.sub('[^a-zA-Z]', ' ', desc)\n",
                "    \n",
                "    #borrar etiquetas especiales\n",
                "    desc=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",desc)\n",
                "    \n",
                "    #borrar digitos y caracteres especiales\n",
                "    desc=re.sub(\"(\\\\d|\\\\W)+\",\" \",desc)\n",
                "    \n",
                "    limpieza.append(desc)\n",
                "\n",
                "#asiganmos los datos limipios en limpieza\n",
                "df_aux['url'] = limpieza\n",
                "        \n",
                "df_aux.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "https          2336\n",
                            "com            2065\n",
                            "www            1512\n",
                            "the             354\n",
                            "html            296\n",
                            "news            274\n",
                            "a               252\n",
                            "us              248\n",
                            "to              218\n",
                            "of              173\n",
                            "coronavirus     172\n",
                            "e               150\n",
                            "org             146\n",
                            "c               136\n",
                            "article         131\n",
                            "b               124\n",
                            "in              115\n",
                            "and             113\n",
                            "morningbrew     105\n",
                            "story           105\n",
                            "nytimes         101\n",
                            "on              101\n",
                            "daily            99\n",
                            "d                98\n",
                            "stories          94\n",
                            "utm              90\n",
                            "for              90\n",
                            "youtube          89\n",
                            "v                89\n",
                            "trump            88\n",
                            "numlock          87\n",
                            "watch            86\n",
                            "f                78\n",
                            "is               77\n",
                            "new              76\n",
                            "p                69\n",
                            "world            68\n",
                            "substack         68\n",
                            "reuters          65\n",
                            "covid            63\n",
                            "s                62\n",
                            "briefingday      61\n",
                            "index            61\n",
                            "vox              59\n",
                            "en               59\n",
                            "articles         58\n",
                            "cnn              58\n",
                            "iduskbn          58\n",
                            "politics         56\n",
                            "co               56\n",
                            "n                54\n",
                            "cnbc             54\n",
                            "sunday           51\n",
                            "business         49\n",
                            "court            48\n",
                            "apnews           47\n",
                            "u                46\n",
                            "facebook         46\n",
                            "email            46\n",
                            "health           45\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux['url'].str.split(expand=True).stack().value_counts()[:60]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creamos una lista de stopwords\n",
                "stop_words = ['http','www','com','you','your','for','not','have','is','in','im','from','to','https','e','c','v','b','f','p']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def remove_stopwords(message):\n",
                "  if message is not None:\n",
                "    words = message.strip().split()\n",
                "    words_filtered = []\n",
                "    for word in words:\n",
                "      if word not in stop_words:\n",
                "        words_filtered.append(word) \n",
                "    result = \" \".join(words_filtered)         \n",
                "  else:\n",
                "    result = None\n",
                "\n",
                "  return result \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_aux['url']=df_aux['url'].apply(remove_stopwords)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>507</th>\n",
                            "      <td>news sky video puerto rico hit by saharan dust...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>256</th>\n",
                            "      <td>cnn us us coronavirus sunday index html</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>432</th>\n",
                            "      <td>pudding cool music challenge</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>419</th>\n",
                            "      <td>apnews afb ea ae ce a ddd</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>704</th>\n",
                            "      <td>goodhousekeeping uk lifestyle a relate researc...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>978</th>\n",
                            "      <td>mowned</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2233</th>\n",
                            "      <td>numlock substack numlock sunday john jackson m...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1999</th>\n",
                            "      <td>cariuma pages mb jun</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2344</th>\n",
                            "      <td>marketwatch story consumer confidence jumps mo...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1846</th>\n",
                            "      <td>str press release us hotel demand expected ful...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                    url  is_spam\n",
                            "507   news sky video puerto rico hit by saharan dust...        0\n",
                            "256             cnn us us coronavirus sunday index html        0\n",
                            "432                        pudding cool music challenge        0\n",
                            "419                           apnews afb ea ae ce a ddd        0\n",
                            "704   goodhousekeeping uk lifestyle a relate researc...        0\n",
                            "978                                              mowned        0\n",
                            "2233  numlock substack numlock sunday john jackson m...        1\n",
                            "1999                               cariuma pages mb jun        0\n",
                            "2344  marketwatch story consumer confidence jumps mo...        0\n",
                            "1846  str press release us hotel demand expected ful...        0"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "the            354\n",
                            "html           296\n",
                            "news           274\n",
                            "a              252\n",
                            "us             248\n",
                            "of             173\n",
                            "coronavirus    172\n",
                            "org            146\n",
                            "article        131\n",
                            "and            113\n",
                            "story          105\n",
                            "morningbrew    105\n",
                            "on             101\n",
                            "nytimes        101\n",
                            "daily           99\n",
                            "d               98\n",
                            "stories         94\n",
                            "utm             90\n",
                            "youtube         89\n",
                            "trump           88\n",
                            "numlock         87\n",
                            "watch           86\n",
                            "new             76\n",
                            "world           68\n",
                            "substack        68\n",
                            "reuters         65\n",
                            "covid           63\n",
                            "s               62\n",
                            "index           61\n",
                            "briefingday     61\n",
                            "vox             59\n",
                            "en              59\n",
                            "cnn             58\n",
                            "iduskbn         58\n",
                            "articles        58\n",
                            "politics        56\n",
                            "co              56\n",
                            "n               54\n",
                            "cnbc            54\n",
                            "sunday          51\n",
                            "business        49\n",
                            "court           48\n",
                            "apnews          47\n",
                            "u               46\n",
                            "email           46\n",
                            "facebook        46\n",
                            "health          45\n",
                            "be              41\n",
                            "supreme         41\n",
                            "bbc             41\n",
                            "blog            40\n",
                            "are             40\n",
                            "black           39\n",
                            "medium          39\n",
                            "police          38\n",
                            "npr             38\n",
                            "with            37\n",
                            "digg            37\n",
                            "campaign        37\n",
                            "why             36\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_aux['url'].str.split(expand=True).stack().value_counts()[:60]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto es algo que estaba en el material de estudio para poder probar como funciona\n",
                "\n",
                "df['len_url'] = df['url'].apply(lambda x : len(x))\n",
                "df['contains_subscribe'] = df['url'].apply(lambda x : 1 if \"subscribe\" in x else 0)\n",
                "df['contains_hash'] = df['url'].apply(lambda x : 1 if \"#\" in x else 0)\n",
                "df['num_digits'] = df['url'].apply(lambda x : len(\"\".join(_ for _ in x if _.isdigit())) )\n",
                "df['non_https'] = df['url'].apply(lambda x : 1 if \"https\" in x else 0)\n",
                "df['num_words'] = df['url'].apply(lambda x : len(x.split(\"/\")))\n",
                "\n",
                "target = 'is_spam'\n",
                "features = [f for f in df.columns if f not in [\"url\", target]]\n",
                "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ahora que hemos limpiado nuestros datos\n",
                "# procedemos a hacer una copia con el dataset a trabajar en el final\n",
                "df = df_aux.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df['url']\n",
                "y = df['is_spam']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=121)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorizador\n",
                "vec = CountVectorizer(stop_words='english')\n",
                "X_train = vec.fit_transform(X_train).toarray()\n",
                "X_test = vec.transform(X_test).toarray()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " ...\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]\n",
                        " [0 0 0 ... 0 0 0]]\n"
                    ]
                }
            ],
            "source": [
                "print(X_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1776, 4825)"
                        ]
                    },
                    "execution_count": 29,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(593, 4825)"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_test.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['aa' 'aab' 'aaron' ... 'zulalimtm' 'zwift' 'zwn']\n"
                    ]
                }
            ],
            "source": [
                "print(vec.get_feature_names_out())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "nb = MultinomialNB()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "MultinomialNB()"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.956081081081081"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.score(X_train,y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.9173693086003373"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nb.score(X_test,y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.93      0.98      0.96       532\n",
                        "           1       0.68      0.38      0.48        61\n",
                        "\n",
                        "    accuracy                           0.92       593\n",
                        "   macro avg       0.80      0.68      0.72       593\n",
                        "weighted avg       0.91      0.92      0.91       593\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "predictions = nb.predict(X_test)\n",
                "print(classification_report(y_test, predictions))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creando la Matriz\n",
                "\n",
                "message_vectorizer = CountVectorizer().fit_transform(df['url'])\n",
                "\n",
                "# Haciendo el split de los datos\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(message_vectorizer, df['is_spam'], test_size = 0.40, random_state = 121, shuffle = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "cl = svm.SVC(C=1.0, kernel='linear', degree=4, gamma='auto')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.95      0.98      0.96       847\n",
                        "           1       0.72      0.54      0.62       101\n",
                        "\n",
                        "    accuracy                           0.93       948\n",
                        "   macro avg       0.84      0.76      0.79       948\n",
                        "weighted avg       0.92      0.93      0.92       948\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "cl.fit(X_train, y_train)\n",
                "pred = cl.predict(X_test)\n",
                "print(classification_report(y_test, pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "pickle.dump(cl, open('../models/texto_NLP.pkl', 'wb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Si queremos cargar el archivo guardado en la carpeta models\n",
                "\n",
                "load_model = pickle.load(open('../models/texto_NLP.pkl', 'rb'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=4, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=4, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "SVC(degree=4, gamma='auto', kernel='linear')"
                        ]
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "load_model"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
